from sklearn.datasets import load_iris
import pandas as pd


iris = load_iris()


# create a Dataframe from the dataset
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['species'] = iris.target

# Map species (target) to human readable label
df['species'] = df['species'].map({0:'setosa', 1:'versicolor', 2:'virginica'})

# Display the first few rows
print(df.head(100))

## Check missing values
print(df.isnull().sum())

## Encoding categorical data
from sklearn.preprocessing import LabelEncoder

# encoding the column 'species'
label_encoder = LabelEncoder()
df['species_encoded'] = label_encoder.fit_transform(df['species'])

print(df[['species', 'species_encoded']].head())
print(df['species_encoded'].unique())
print(df['species'].unique())



## normalize/standardize numnerical features
from sklearn.preprocessing import StandardScaler

# select only the feature column
features = df.iloc[:,:-2]

# Standardize the data
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)


# Create a new DataFrame with scaled features
features_scaled_df = pd.DataFrame(features_scaled, columns=iris.feature_names)

print(features_scaled_df.head())

## split data into train and test
from sklearn.model_selection import train_test_split

# define    